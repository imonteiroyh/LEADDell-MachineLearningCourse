{
 "cells": [
  {
   "source": [
    "### Tensorflow\n",
    "\n",
    "Importando as bibliotecas necessárias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prática\n",
    "Treine uma rede neural com uma camada intermediária de 50 neurônios, utilizando o Keras e o TensorFlow sobre os dados contidos na variável train_images e usando os rótulos train_labels. Após construído o modelo, apresente a acurácia do projeto sobre os dados de teste (test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#Primeiro, precisamos pré-processar esses dados. Assim, verificamos os valores mínimo e máximo da variável train_images\n",
    "np.unique(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agora, sabemos que todos os pixels das imagens estão com valores entre 0 e 255. Dessa forma, transformaremos esses valores para que fiquem em uma escala de 0 a 1, já que as redes neurais se beneficiam de escalas pequenas, como 0 e 1, apresentando melhores performances.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 50)                39250     \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                510       \n=================================================================\nTotal params: 39,760\nTrainable params: 39,760\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Como pré-processamos os dados, resta-nos criar o modelo solicitado, com uma única camada intermediária com 50 neurônios\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape = (28, 28)), \n",
    "    keras.layers.Dense(50, activation = tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation = tf.nn.softmax)\n",
    "])\n",
    "#Desse modelo, pode-se perceber que há uma camada Flatten para transformar a matriz em um vetor, uma camada Dense intermediária como solicitado, com 50 neurônios que fará o verdadeiro processamento computacional e uma última camada Dense com a função de ativação softmax para classificar as imagens obtidas entre 0 e 9, podemos ver as arquiteturas por\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.6919 - accuracy: 0.7650\n",
      "Epoch 2/4\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4077 - accuracy: 0.8561\n",
      "Epoch 3/4\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3638 - accuracy: 0.8684\n",
      "Epoch 4/4\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3380 - accuracy: 0.8781\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d654bed340>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "#Podemos compilar o modelo utilizando optimizer 'adam' para definir a técnica para a construção dos pesos do treinamento, loss 'sparse_categorical_crossentropy', que é uma técnica boa para trabalhar com resultados com muitos valores próximos a 0 e alguns valores próximos a 1 e metrics 'accuracy' que é a porcentagem de elementos classificados corretamente\n",
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#Treinando o modelo, teremos, considerando 4 épocas, visto que, com mais épocas, o aumento na acurácia era mínimo, com menos de 1% de diferença, não havendo, portanto, necessidade de mais épocas, visto que um maior número de épocas pode ocasionar o overfitting do modelo\n",
    "model.fit(train_images, train_labels, epochs = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3838 - accuracy: 0.8629\n"
     ]
    }
   ],
   "source": [
    "#Finalmente, mostramos a acurácia do modelo como solicitado\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}